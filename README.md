# BAT: Benchmark for Auto-bidding Task

## Overview

This repository contains the benchmark implementation and supplementary materials for our paper "BAT: Benchmark for Auto-bidding Task
" (paper on [OpenReview](https://openreview.net/forum?id=9eRgajXN2w#discussion)). It provides a comprehensive framework for evaluating and comparing different bidding strategies in online advertising auctions.

## Key Features

- Implementation of the following bidding strategies:
  1. ALM
  2. TA-PID
  3. [M-PID](https://arxiv.org/pdf/1905.10928)
  4. [Mystique](https://www.yahooinc.com/research/publications/mystique-a-budget-pacing-system-for-performance-optimization-in-online-advertising)
  5. [BROI](https://arxiv.org/pdf/2301.13306)
- Simulation environment for ad auctions of two types: FPA (First-Price Auction) and VCG (Vickreyâ€“Clarkeâ€“Groves) auction
- Data analysis and visualization tools
- Benchmark datasets

## Repository Structure

```
.
â”œâ”€â”€ ğŸ“œ LICENSE
â”œâ”€â”€ ğŸ“˜ README.md
â”œâ”€â”€ ğŸ“Š data/                          # Data for VCG and FPA (to be downloaded with dvc)
â”‚   â”œâ”€â”€ fpa/
â”‚   â”œâ”€â”€ vcg/
â”œâ”€â”€ ğŸ““ example_notebooks/             # Notebooks with model running examples
â”‚   â”œâ”€â”€ baseline_bidders.ipynb        # Guideline: how to make experiments with bidders
â”‚   â”œâ”€â”€ bidder_example.ipynb          # Guideline: how to create new bidder class
â”‚   â””â”€â”€ ğŸ“Š best_params/
â”œâ”€â”€ ğŸ“‹ requirements.txt
â”œâ”€â”€ ğŸ› ï¸ simulator/                      # Main simulator code
â”‚   â”œâ”€â”€ ğŸ’° model/                      # Bidder models
â”‚   â”‚   â”œâ”€â”€ bidder.py                  # Parent class for all bidders
â”‚   â”‚   â”œâ”€â”€ broi_bidder.py           
â”‚   â”‚   â”œâ”€â”€ linear_bidder.py           # ALM bidder implementation
â”‚   â”‚   â”œâ”€â”€ m_pid.py                
â”‚   â”‚   â”œâ”€â”€ mystique.py               
â”‚   â”‚   â”œâ”€â”€ ta_pid.py
â”‚   â”‚   â””â”€â”€ traffic.py
â”‚   â”œâ”€â”€ ğŸ”„ simulation/                 # Modules for running simulations
â”‚   â”‚   â”œâ”€â”€ modules.py
â”‚   â”‚   â”œâ”€â”€ simulate.py
â”‚   â”‚   â”œâ”€â”€ utils.py
â”‚   â”‚   â””â”€â”€ utils_visualization.py
â”‚   â””â”€â”€ âœ… validation/                 # Running experiments on all campaigns
â”‚       â”œâ”€â”€ check_results.py
â”‚       â””â”€â”€ metrics.py
â””â”€â”€ ğŸ“” useful_notebooks/              # Notebooks with data filtering examples
    â”œâ”€â”€ filter-fpa.ipynb
    â””â”€â”€ filter-vcg.ipynb
```

### Installation

1. Clone the repository: `git clone https://github.com/avito/your-repo-name.git`
2. Install the required packages: `pip install -r requirements.txt`
3. Download data: `dvc pull`

### Experiment Results

The Sum Click Ratio (SCR) for the proposed models:

| Model      | SCR<sup>VCG</sup> | SCR<sup>FP</sup> |
|------------|-------------------|------------------|
| ALM        | 662,466           | 1,085,836        |
| TA-PID     | 909,282           | 1,478,538        |
| M-PID      | 889,251           | 1,240,244        |
| Mystique   | 932,152           | 1,073,291        |
| BROI       | 495,169           | 1,098,184        |

## Contributing

We welcome contributions to improve the benchmark. Please feel free to submit issues or pull requests.

## Citation

If you use this benchmark in your research, please cite our paper: 

```
@inproceedings{khirianova2025bat,
  title={BAT: Benchmark for Auto-bidding Task},
  author={Khirianova, Alexandra and Solodneva, Ekaterina and Pudovikov, Andrey and Osokin, Sergey and Samosvat, Egor and Dorn, Yuriy and Ledovsky, Alexander and Zenkova, Yana},
  booktitle={Proceedings of the ACM on Web Conference 2025},
  pages={2657--2667},
  year={2025}
}
```

## License

This project is licensed under MIT License. See the LICENSE file for details. 

[![DOI](https://zenodo.org/badge/doi/10.5281/zenodo.14795981.svg)](http://dx.doi.org/10.5281/zenodo.14795981)

